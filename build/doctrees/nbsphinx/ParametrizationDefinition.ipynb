{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d66239e",
   "metadata": {},
   "source": [
    "## ParametrizationDefinition\n",
    "\n",
    "In order to estimate multimodal features of neurophysiological data, certain parametrization steps are required. \n",
    "Here the following two parametrization files are explained: \n",
    " - `nm_settings.json`\n",
    " - `nm_channels.csv`\n",
    " \n",
    "### Preprocessing \n",
    "\n",
    "The following preprocessing options can be written in the *preprocessing* field, **which will be executed in the specified order**:\n",
    "```json\n",
    "\"documentation_preprocessing_options\": [\n",
    "    \"raw_resampling\",\n",
    "    \"notch_filter\",\n",
    "    \"re_referencing\",\n",
    "    \"raw_normalization\"\n",
    "],\n",
    "```\n",
    "#### Resampling\n",
    "**raw_resampling** defines a resampling rate to which the original data is downsampled to. This can be of advantage, since high sampling frequencies automatically require usually more computational cost. In the method specific settings the resampling frequency can be defined: \n",
    "\n",
    "```json\n",
    "\"raw_resampling_settings\": {\n",
    "    \"resample_freq_hz\": 1000\n",
    "}\n",
    "```\n",
    "#### Notch Filtering\n",
    "**notch_filer** is a simple setting that filters at the specified *line_noise* frequency supplied to *Stream* class.\n",
    "\n",
    "#### Rereferencing\n",
    "\n",
    "**rereferencing** constitutes an important aspect of electrophysiological signal processing. Most commonly bipolar and common average rereferencing are applied for separate channel modalities. The channel specific *rereferencing* is specified in the  *nm_channels* dataframe in the *rereference* column, with the following possible combinations:\n",
    "\n",
    "|Rereference Type|Description|Example|\n",
    "| --- | --- | --- |\n",
    "| average | common average rereference (across a channel type, e.g. ecog or eeg)| *average* |\n",
    "|bipolar|bipolar rereferencing, by specifying the channel name to rereference to|*LFP_RIGHT_0*|\n",
    "|combination|combination of different channels separated by \"&\" can also be used|*LFP_RIGHT_0&LFP_RIGHT_1*|\n",
    "|none|no rereferencing being used for this particular channel|*none*\n",
    "\n",
    "#### Normalization\n",
    "**normalization** allows for normalizing the past *normalization_time* according to the following options:\n",
    " - mean\n",
    " - median\n",
    " - zscore\n",
    " - zscore-median\n",
    " - quantile\n",
    " - power\n",
    " - robust\n",
    " - minmax\n",
    "\n",
    "The latter four options are obtained via wrappers around the [scikit-learn preprocessing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) modules.\n",
    "\n",
    "*zscore-median* is implemented using the following equation:\n",
    "$X_{norm} = \\frac{X - median(X)}{median(X)}$\n",
    "\n",
    "The *normalization_time* allows to specify a **past** time window that will be used for normalization. The setting specification for *raw* and *feature* normalization is specified in the same manner:\n",
    "\n",
    "```json\n",
    "\"raw_normalization_settings\": {\n",
    "        \"normalization_time\": 10,\n",
    "        \"normalization_method\": \"median\"\n",
    "    }\n",
    "\n",
    "```\n",
    "\n",
    "### Features\n",
    "\n",
    "Features can be enabled and disabled in the *features* key: \n",
    "```json\n",
    "\"features\": \n",
    "{\n",
    "        \"raw_hjorth\": true,\n",
    "        \"return_raw\": true,\n",
    "        \"bandpass_filter\": true,\n",
    "        \"stft\": true,\n",
    "        \"fft\": true,\n",
    "        \"sharpwave_analysis\": true,\n",
    "        \"coherence\": true,\n",
    "        \"fooof\": true,\n",
    "        \"nolds\": true,\n",
    "        \"bursts\": true,\n",
    "        \"linelength\": true,\n",
    "        \"mne_connectivity\": true\n",
    "}\n",
    "```\n",
    "\n",
    "#### Oscillatory Features\n",
    "\n",
    "##### Frequency Band specification\n",
    "\n",
    "Frequency bands are specified in the settings within a dictionary of frequency band names and a list of lower and upper band ranges. The supplied frequency ranges can be utilized by different feature modalities, e.g. fft, coherence, sharpwave etc.\n",
    "\n",
    "```json\n",
    "    \"frequency_ranges_hz\": {\n",
    "        \"theta\": [\n",
    "            4,\n",
    "            8\n",
    "        ],\n",
    "        \"alpha\": [\n",
    "            8,\n",
    "            12\n",
    "        ],\n",
    "```\n",
    "\n",
    "##### FFT and STFT\n",
    "Fast Fourier Transform and Short-Time Fourier Transform are both specified using the same settings parametrization:\n",
    "```json\n",
    "    \"fft_settings\": {\n",
    "        \"windowlength_ms\": 1000,\n",
    "        \"log_transform\": true,\n",
    "        \"kalman_filter\": false\n",
    "    }\n",
    "```\n",
    "*log_transform* is here a recommended setting.\n",
    "\n",
    "##### Kalman filtering\n",
    "**kalman_filter** can be enabled for all oscillatory features and is motivated by filtering estimated band power features using the white noise acceleration model (see [\"Improved detection of Parkinsonian resting tremor with feature engineering and Kalman filtering\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6927801/) Yao et al 19) for a great reference. The white noise acceleration model get's specified by the $T_p$ prediction interval (Hz), and the process noise is then defined by $\\sigma_w$ and $\\sigma_v$: \n",
    "\n",
    "$\n",
    "  Q=\n",
    "  \\left[ {\\begin{array}{cc}\n",
    "   \\sigma_w^2\\frac{T_p^{3}}{3} & \\sigma_w^2\\frac{T_p^2}{2}\\\\\n",
    "   \\sigma_w^2\\frac{T_p^2}{3} & \\sigma_w^2T_p\\\\\n",
    "  \\end{array} } \\right]\n",
    "$\n",
    "\n",
    "The settings can be specified as follows:\n",
    "\n",
    "```json\n",
    "\"kalman_filter_settings\": {\n",
    "        \"Tp\": 0.1,\n",
    "        \"sigma_w\": 0.7,\n",
    "        \"sigma_v\": 1,\n",
    "        \"frequency_bands\": [\n",
    "            \"low gamma\",\n",
    "            \"high gamma\",\n",
    "            \"all gamma\"\n",
    "        ]\n",
    "    }\n",
    "```\n",
    "Individual frequency bands (specified in the *frequency_ranges_hz*) can be selected for Kalman Filtering (see [\"Real-time epileptic seizure prediction using AR models and support vector machines\"](https://pubmed.ncbi.nlm.nih.gov/20172805/) (Chisci et al 10) fir and example). \n",
    "\n",
    "**bandpass_filter** enables band power feature estimation through precomputation of a FIR filter using the [mne.filter.create_filter](https://mne.tools/dev/generated/mne.filter.create_filter.html) function. Settings are defined in such manner: \n",
    "```json\n",
    "\"bandpass_filter_settings\": {\n",
    "    \"segment_lengths_ms\": {\n",
    "        \"theta\": 1000,\n",
    "        \"alpha\": 500,\n",
    "        \"low beta\": 333,\n",
    "        \"high beta\": 333,\n",
    "        \"low gamma\": 100,\n",
    "        \"high gamma\": 100,\n",
    "        \"HFA\": 100\n",
    "    },\n",
    "    \"bandpower_features\": {\n",
    "        \"activity\": true,\n",
    "        \"mobility\": false,\n",
    "        \"complexity\": false\n",
    "    },\n",
    "    \"log_transform\": true,\n",
    "    \"kalman_filter\": false\n",
    "}\n",
    "```\n",
    "\n",
    "The *segment_length_ms* parameter defines a time range in which FIR filtered data is used for feature estimation. Here for the theta frequency band the previous 1000 ms are used to estimate features based on the FIR filtered signal. This might be beneficial when using shorter frequency bands, e.g. gamma, where estimating band power in a range of e.g. 100 ms might result in a temporal more specified feature calculation. \n",
    "A common way to estimate band power is to take the variance of FIR filtered data. This is equavilent to the activity [Hjorth](https://en.wikipedia.org/wiki/Hjorth_parameters) parameter. The last key in the *bandpass_filter_settings* allows to take the *activity*, *mobility* and *complexity* Hjorth parameters as well. For estimating Hjorth parameters of the raw unfiltered signal, the **raw_hjorth** method can be enabled. \n",
    "\n",
    "**sharpwave_analysis** allows for calculation of temporal sharpwave features. See [\"Brain Oscillations and the Importance of Waveform Shape\"](https://www.sciencedirect.com/science/article/abs/pii/S1364661316302182) Cole et al 17 for a great motivation to use these features. Here, sharpwave features are estimated using a prior bandpass filter  between *filter_low_cutoff* and *filter_high_cutoff*. The sharpwave peak and trough features can be calculated, defined by the *estimate* key. According to a current data batch one or more sharpwaves can be detected. The subsequent feature is returned rather by the *mean, median, maximum, minimum or variance* as defined by the *estimator*. \n",
    "```json\n",
    "\"sharpwave_analysis_settings\": {\n",
    "    \"sharpwave_features\": {\n",
    "        \"peak_left\": false,\n",
    "        \"peak_right\": false,\n",
    "        \"trough\": false,\n",
    "        \"width\": false,\n",
    "        \"prominence\": true,\n",
    "        \"interval\": true,\n",
    "        \"decay_time\": false,\n",
    "        \"rise_time\": false,\n",
    "        \"sharpness\": true,\n",
    "        \"rise_steepness\": false,\n",
    "        \"decay_steepness\": false,\n",
    "        \"slope_ratio\": false\n",
    "    },\n",
    "    \"filter_ranges_hz\": [\n",
    "        [\n",
    "            5,\n",
    "            80\n",
    "        ],\n",
    "        [\n",
    "            5,\n",
    "            30\n",
    "        ]\n",
    "    ],\n",
    "    \"detect_troughs\": {\n",
    "        \"estimate\": true,\n",
    "        \"distance_troughs_ms\": 10,\n",
    "        \"distance_peaks_ms\": 5\n",
    "    },\n",
    "    \"detect_peaks\": {\n",
    "        \"estimate\": true,\n",
    "        \"distance_troughs_ms\": 5,\n",
    "        \"distance_peaks_ms\": 10\n",
    "    },\n",
    "    \"estimator\": {\n",
    "        \"mean\": [\n",
    "            \"interval\"\n",
    "        ],\n",
    "        \"median\": null,\n",
    "        \"max\": [\n",
    "            \"prominence\",\n",
    "            \"sharpness\"\n",
    "        ],\n",
    "        \"min\": null,\n",
    "        \"var\": null\n",
    "    },\n",
    "    \"apply_estimator_between_peaks_and_troughs\": true\n",
    "}\n",
    "```\n",
    "A separate tutorial on sharpwave features is provided in the documentation. \n",
    "\n",
    "Next, raw signals can be returned, specifed by the **return_raw** method.\n",
    "\n",
    "### Postprocessing\n",
    "\n",
    "**projection_cortex** and **projection_subcortex** allows then feature projection of individual channels to a common subcortical or cortical grid, defined by *grid_cortex.tsv* and *subgrid_cortex.tsv*. For both projections a *max_dist* parameter needs to be specified, in which data is linearly interpolated, weighted by their inverse grid point distance. \n",
    "\n",
    "Additionally **pdc** and **dtf** enable partical directed coherence and direct transfer function, to enable connectiviy features for certain *frequency_bands* between specific channels. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyneuromodulation",
   "language": "python",
   "name": "pyneuromodulation"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 | packaged by conda-forge | (default, Jul 11 2021, 03:37:25) [MSC v.1916 64 bit (AMD64)]"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
